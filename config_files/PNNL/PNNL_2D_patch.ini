[META]
# these are keys that need to be changed for different compute platforms
output_storage = /p/vast1/bartolds/CCSI/logs
#output_storage = /data/ccsi/logs
raw_data_storage = /p/vast1/ccsi/PNNL_2020/t_equal_zero_and_pnnl_node_types/
#raw_data_storage = /data/ccsi/PNNL_2020/

[DATA]
# dataset class
class_name = PNNL_Subdomain
name = PNNL_Data

# graph construction parameters
boundary_node_types = []
source_node_types = [3] 
graph_type = delaunay 
k = 6 
radius = 0.01

# processing params
output_type = velocity
window_length = 1
apply_onehot = True
noise = [0.02, 0.03, 0.05]
noise_gamma = 0.1
normalize = True

[MODEL]
mgn_dim = 128
mp_iterations = 15
mlp_norm_type = LayerNorm
normalize_output = True

[TRAINING]
# hyperparams
epochs = 100
steps = 4e6 # overrides epochs
batch_size = 1 # 12 # should be 12 / world_size
grad_accum_steps = 1
lr = 1e-3
weight_decay = 0
scheduler = ExpLR
use_parallel = False
validation_time_limit = 1
sample_limit = 500

# can be one of [last_epoch, best_val]
load_prefix = last_epoch

# logging
expt_name = pnnl_2D_patch_training
log_rate = 100
use_tensorboard = True
tb_rate = 10
save_interval = 3e4 # num epochs if not using step-based training, else num steps
run_rollout_at_interval = False
# expt_name = overfitddp_momentum${DATA:momentum}_bz${TRAINING:batch_size}_${DATA:noise}_noisegamma_${DATA:noise_gamma}_name_${DATA:name}_mgndim_${MODEL:mgn_dim}_mpiterations_${MODEL:mp_iterations}_${TRAINING:scheduler}_${TRAINING:lr}_${DATA:sim_range}_DP_${TRAINING:use_parallel}_DS_${DATA:class_name}_ddphook_${TRAINING:ddp_hook}
train_output_dir = ${META:output_storage}/train
checkpoint_dir = ${TRAINING:train_output_dir}/checkpoints/${TRAINING:expt_name}
log_dir = ${TRAINING:train_output_dir}/logs/${TRAINING:expt_name}
tensorboard_dir = ${TRAINING:train_output_dir}/tensorboard/${TRAINING:expt_name}

# 'mean' for default DDP behavior, or 'sum'
ddp_hook = mean
pin_memory=True

# world_size should be the total number of gpus across all nodes (1 process per gpu)
world_size = 12
data_num_workers = 4

[SCHEDULER]
# ExpLR
scheduler_decay_interval = 0.5
gamma = 0.01
min_lr = 1e-8
# uncomment below to manually set decay steps, otherwise it'll automatically compute it.
# decay_steps = 4e6

# OneCycle
max_lr = 3e-2

# ReduceLROPlateau
patience = 50

[TESTING]
do_rollout_test = True
rollout_start_idx = 0
test_output_dir = ${META:output_storage}/test
outfile = ${TESTING:test_output_dir}/rollout.pk
batch_size = 2 #56

# --------------- EXTRA PARAMS (auto forwarded via **kwargs) ---------------
[PNNL_PARAMS]
root_dir = ${META:raw_data_storage}
partition_method = range
output_dim = 3
thickness=15
same_xy = True
momentum = True

sim_range = [5,6,7,8,9,10,11,	13,14,15,16,17,18,19,20,	22,23,24,25,26,27,28,29,	31,32,33,34,35,36,37,38,	40,41,42,43,44,45,46]
time_range = [0,500]
x_range = "3, -0.0505, 0.0505"
y_range = "4, 0.09, 0.21"

test_sim_range = [1, 2, 3, 4, 12, 21, 30, 39, 47, 48, 49, 50 ]
test_time_range = ${PNNL_PARAMS:time_range}
test_x_range = [(-0.0505, 0.0505)]
test_y_range = [(0.09, 0.21)]
